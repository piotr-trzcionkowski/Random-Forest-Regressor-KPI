#Automatically generated by Colaboratory.
#
#importing required libraries
import pandas as pd
import numpy as np
from pandas import DataFrame
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

#importing and preparing training data
X_train = pd.read_csv("X_train.csv", delimiter=';', decimal=',')
Y_train = pd.read_csv("Y_train.csv", delimiter=';', decimal=',')

X_train.drop(['key', 'date'], inplace=True, axis=1)
Y_train.drop(['key', 'date'], inplace=True, axis=1)
X_train.fillna(0, inplace=True)
Y_train.fillna(0, inplace=True)


#importing and preparing predction data 
X_test = pd.read_csv("X_test.csv", delimiter=';', decimal=',')
Y_test = pd.read_csv("Y_test.csv", delimiter=';', decimal=',')

X_test.drop(['key', 'date'], inplace=True, axis=1)
X_test.fillna(0, inplace=True)

#preparing data to determine hyperparameters for RandomForestRegressor function
xtraining, xtesting, ytraining, ytesting = train_test_split(X_train, Y_train, test_size = 0.25)

### This part was used to determine hyperaparameters on above prepared datasets ###
# estimators = np.linspace(20, 30, 11, dtype=int)
# MaxDepth=np.linspace(30, 50, 21, dtype=int)
# for i in MaxDepth:
rfr = RandomForestRegressor(n_estimators = 25, random_state=10 , n_jobs=-1, max_depth=34)
rfr.fit(xtraining, ytraining.values.ravel())
y_predrfr = rfr.predict(xtesting)
WMAPE = (ytesting.sum()-y_predrfr.sum())/ytesting.sum()*100
print("Estimators: 25\tMax Depth: 34\t WMAPE: %f %%" %(WMAPE))

#training RandomForestRegressor algorithm
rfr = RandomForestRegressor(n_estimators = 25, random_state=None , n_jobs=-1, max_depth=34)
rfr.fit(X_train, Y_train.values.ravel())

#predicting Y_test.csv data
y_predicted = rfr.predict(X_test)
Y_test['y'] = y_predicted

print(Y_test)

#exporting predicted data back to .csv file
Y_test.to_csv('Y_test_filled.csv', sep=';', decimal=',', index=False)
